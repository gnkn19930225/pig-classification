## æ¦‚è¿°

æœ¬å°ˆæ¡ˆä½¿ç”¨ **ResNet** æ¶æ§‹é€²è¡Œå½±åƒåˆ†é¡ä»»å‹™ï¼Œæ¡ç”¨äº†å¤šé …é€²éšè¨“ç·´æŠ€å·§ä¾†æå‡æ¨¡å‹æ€§èƒ½ä¸¦é¿å…éæ“¬åˆã€‚

### åŸºæœ¬è¨­å®š

- **æ¨¡å‹æ¶æ§‹**: ResNet
- **è¼¸å…¥å°ºå¯¸**: 360 Ã— 640 Ã— 3 (æ”å½±æ©Ÿæœ€å°å°ºå¯¸)
- **é¡åˆ¥æ•¸é‡**: 3 é¡(æœ‰è±¬ã€æ²’è±¬å’Œæ”å½±æ©Ÿæ•…éšœ)
- **æ‰¹æ¬¡å¤§å°**: 32
- **æœ€å¤§è¨“ç·´è¼ªæ•¸**: 1000 epochs
- **è¨“ç·´/é©—è­‰æ¯”ä¾‹**: 80% / 20%

---

## è¨“ç·´ç­–ç•¥

### 1. ğŸ² éš¨æ©Ÿç¨®å­ç­–ç•¥

æ¯æ¬¡è¨“ç·´ä½¿ç”¨**éš¨æ©Ÿç”¢ç”Ÿçš„ç¨®å­**ï¼Œç¢ºä¿è³‡æ–™åˆ†å‰²çš„å¤šæ¨£æ€§ï¼š

```python
random_seed = random.randint(1, 10000)
print(f"ä½¿ç”¨éš¨æ©Ÿç¨®å­: {random_seed}")
```

**å„ªé»ï¼š**

- é¿å…æ¨¡å‹éåº¦ä¾è³´ç‰¹å®šçš„è³‡æ–™åˆ†å‰²
- å¢åŠ è¨“ç·´çš„æ³›åŒ–èƒ½åŠ›
- æ¯æ¬¡è¨“ç·´éƒ½èƒ½æ¢ç´¢ä¸åŒçš„è³‡æ–™åˆ†å¸ƒ
- **è¨“ç·´çµæŸæ™‚èƒ½å¤ æ¸¬è©¦ä¸åŒçš„é©—è­‰é›†**

### 2. ğŸ“‰ è‡ªå‹•å­¸ç¿’ç‡èª¿æ•´ (ReduceLROnPlateau)

ç•¶é©—è­‰æå¤±ä¸å†ä¸‹é™æ™‚ï¼Œ**è‡ªå‹•é™ä½å­¸ç¿’ç‡**ï¼š

```python
lr_reducer = ReduceLROnPlateau(
    monitor='val_loss',      # ç›£æ§é©—è­‰æå¤±
    factor=0.5,              # å­¸ç¿’ç‡é™ä½ç‚ºåŸæœ¬çš„ 50%
    patience=5,              # 5 å€‹ epoch æ²’æ”¹å–„å°±é™ä½
    min_lr=1e-6              # æœ€å°å­¸ç¿’ç‡é™åˆ¶
)
```

**å·¥ä½œåŸç†ï¼š**

- æŒçºŒç›£æ§ `val_loss`
- å¦‚æœé€£çºŒ 5 å€‹ epoch æ²’æœ‰æ”¹å–„
- å­¸ç¿’ç‡ Ã— 0.5ï¼ˆä¾‹å¦‚ï¼š0.001 â†’ 0.0005ï¼‰
- ç›´åˆ°å­¸ç¿’ç‡é”åˆ°æœ€å°å€¼ 1e-6

### 3. â¹ï¸ æ—©åœæ©Ÿåˆ¶ (EarlyStopping)

ç•¶æ¨¡å‹æ€§èƒ½ä¸å†æå‡æ™‚ï¼Œ**è‡ªå‹•åœæ­¢è¨“ç·´**ï¼š

```python
early_stopping = EarlyStopping(
    monitor='val_loss',           # ç›£æ§é©—è­‰æå¤±
    patience=10,                  # 10 å€‹ epoch æ²’æ”¹å–„å°±åœæ­¢
    restore_best_weights=True     # æ¢å¾©æœ€ä½³æ¬Šé‡
)
```

**å„ªé»ï¼š**

- é˜²æ­¢éåº¦è¨“ç·´ï¼ˆoverfittingï¼‰
- ç¯€çœè¨“ç·´æ™‚é–“å’Œé‹ç®—è³‡æº
- è‡ªå‹•æ¢å¾©åˆ°é©—è­‰è¡¨ç¾æœ€ä½³çš„æ¬Šé‡

### 4. ğŸ’¾ æœ€ä½³æ¨¡å‹ä¿å­˜ (BestModelCheckpoint)

**è‡ªè¨‚å›èª¿å‡½æ•¸**ï¼Œåªä¿ç•™é©—è­‰æº–ç¢ºç‡æœ€é«˜çš„æ¨¡å‹æ¬Šé‡ï¼š

```python
class BestModelCheckpoint(Callback):
    def __init__(self, filepath_template, monitor='val_accuracy', mode='max'):
        # åˆå§‹åŒ–åƒæ•¸
        self.best = -float('inf')  # æœ€ä½³æº–ç¢ºç‡
        self.current_filepath = None
    
    def on_epoch_end(self, epoch, logs=None):
        current = logs.get(self.monitor)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ”¹å–„
        if current > self.best:
            # åˆªé™¤èˆŠçš„æ¬Šé‡æª”æ¡ˆ
            if self.current_filepath and os.path.exists(self.current_filepath):
                os.remove(self.current_filepath)
            
            # ä¿å­˜æ–°çš„æœ€ä½³æ¬Šé‡
            self.best = current
            new_filepath = self.filepath_template.format(val_accuracy=current)
            self.model.save_weights(new_filepath)
            self.current_filepath = new_filepath
```

**ç‰¹é»ï¼š**

- è‡ªå‹•åˆªé™¤èˆŠçš„æ¬Šé‡æª”æ¡ˆï¼Œç¯€çœç£ç¢Ÿç©ºé–“
- æª”æ¡ˆåç¨±åŒ…å«æº–ç¢ºç‡ï¼Œæ–¹ä¾¿è­˜åˆ¥
- æª”æ¡ˆåç¨±æ ¼å¼ï¼š`best_resnet_model_360x640_{æ—¥æœŸæ™‚é–“}_rs{éš¨æ©Ÿç¨®å­}_val_acc_{æº–ç¢ºç‡}.h5`

### 5. ğŸ”„ è³‡æ–™å¢å¼· (Data Augmentation)

**è¨“ç·´é›†**ä½¿ç”¨å¤§é‡è³‡æ–™å¢å¼·æŠ€è¡“ï¼š

```python
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=40,              # éš¨æ©Ÿæ—‹è½‰ Â±40åº¦
    width_shift_range=0.3,          # æ°´å¹³å¹³ç§» Â±30%
    height_shift_range=0.3,         # å‚ç›´å¹³ç§» Â±30%
    zoom_range=0.2,                 # éš¨æ©Ÿç¸®æ”¾ Â±20%
    shear_range=0.2,                # å‰ªåˆ‡è®Šæ› Â±20%
    brightness_range=[0.8, 1.2],    # äº®åº¦èª¿æ•´ 80%-120%
    horizontal_flip=True            # éš¨æ©Ÿæ°´å¹³ç¿»è½‰
)
```

**é©—è­‰é›†**ä¸é€²è¡Œè³‡æ–™å¢å¼·ï¼š

```python
val_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input  # åƒ…æ¨™æº–åŒ–
)
```

---

## æ ¸å¿ƒæŠ€è¡“ç´°ç¯€

### è³‡æ–™åˆ†å‰²æµç¨‹

1. **è®€å–åŸå§‹è³‡æ–™å¤¾çµæ§‹**

   ```
   data/
   â”œâ”€â”€ é¡åˆ¥1/
   â”‚   â”œâ”€â”€ image1.jpg
   â”‚   â””â”€â”€ image2.jpg
   â”œâ”€â”€ é¡åˆ¥2/
   â””â”€â”€ é¡åˆ¥3/
   ```

2. **ä½¿ç”¨ `train_test_split` åˆ†å‰²**

   - æ¯å€‹é¡åˆ¥ç¨ç«‹åˆ†å‰²ï¼ˆä¿æŒé¡åˆ¥å¹³è¡¡ï¼‰
   - 80% è¨“ç·´ï¼Œ20% é©—è­‰
   - ä½¿ç”¨éš¨æ©Ÿç¨®å­ç¢ºä¿å¯é‡ç¾

3. **å»ºç«‹è‡¨æ™‚ç›®éŒ„çµæ§‹**

   ```
   temp_train/          temp_val/
   â”œâ”€â”€ é¡åˆ¥1/          â”œâ”€â”€ é¡åˆ¥1/
   â”œâ”€â”€ é¡åˆ¥2/          â”œâ”€â”€ é¡åˆ¥2/
   â””â”€â”€ é¡åˆ¥3/          â””â”€â”€ é¡åˆ¥3/
   ```

4. **è¨“ç·´å®Œæˆå¾Œè‡ªå‹•æ¸…ç†è‡¨æ™‚ç›®éŒ„**

### éŒ¯èª¤æ¡ˆä¾‹åˆ†æ

è¨“ç·´å®Œæˆå¾Œï¼Œç³»çµ±æœƒ**è‡ªå‹•åˆ†æä¸¦é¡¯ç¤ºæ‰€æœ‰åˆ†é¡éŒ¯èª¤çš„æ¡ˆä¾‹**ï¼š

```python
# æ‰¾å‡ºæ‰€æœ‰åˆ†éŒ¯çš„åœ–ç‰‡
for i in range(len(predicted_labels)):
    if predicted_labels[i] != true_labels[i]:
        wrong_predictions.append({
            'filename': val_filenames[i],
            'true_label': class_names[true_labels[i]],
            'predicted_label': class_names[predicted_labels[i]],
            'confidence': predictions[i][predicted_labels[i]]
        })

# æ‰“å°è©³ç´°è³‡è¨Š
print(f"\nç¸½å…±æ‰¾åˆ° {len(wrong_predictions)} å¼µåˆ†éŒ¯çš„åœ–ç‰‡ï¼š")
for i, wp in enumerate(wrong_predictions, 1):
    print(f"{i:3d}. {os.path.basename(wp['filename'])}")
    print(f"     True Label: {wp['true_label']}")
    print(f"     Predicted Label: {wp['predicted_label']}")
    print(f"     Confidence: {wp['confidence']:.4f}")
```

**è¼¸å‡ºç¯„ä¾‹ï¼š**

```
ç¸½å…±æ‰¾åˆ° 15 å¼µåˆ†éŒ¯çš„åœ–ç‰‡ï¼š
================================================================================
  1. image_0045.jpg
     True Label: é¡åˆ¥A
     Predicted Label: é¡åˆ¥B
     Confidence: 0.8523
------------------------------------------------------------
  2. image_0123.jpg
     True Label: é¡åˆ¥B
     Predicted Label: é¡åˆ¥C
     Confidence: 0.6741
```

æ¯å¼µéŒ¯èª¤åœ–ç‰‡æœƒè‡ªå‹•é¡¯ç¤ºï¼Œæ¨™é¡ŒåŒ…å«ï¼š

- æª”æ¡ˆåç¨±
- çœŸå¯¦æ¨™ç±¤ vs é æ¸¬æ¨™ç±¤
- æ¨¡å‹ä¿¡å¿ƒåº¦

---

## è¨“ç·´æµç¨‹åœ–

### æ•´é«”è¨“ç·´æµç¨‹

```mermaid
flowchart TD
    Start([é–‹å§‹è¨“ç·´]) --> RandomSeed[ç”¢ç”Ÿéš¨æ©Ÿç¨®å­<br/>1-10000]
    RandomSeed --> SplitData[è³‡æ–™åˆ†å‰²<br/>80% è¨“ç·´ / 20% é©—è­‰]
    SplitData --> CreateTemp[å»ºç«‹è‡¨æ™‚ç›®éŒ„<br/>temp_train / temp_val]
    CreateTemp --> LoadData[è¼‰å…¥è³‡æ–™<br/>å«è³‡æ–™å¢å¼·]
    LoadData --> CreateModel[å»ºç«‹ ResNet æ¨¡å‹]
    CreateModel --> SetCallbacks[è¨­å®šå›èª¿å‡½æ•¸<br/>- BestModelCheckpoint<br/>- EarlyStopping<br/>- ReduceLROnPlateau]
    SetCallbacks --> TrainLoop[é–‹å§‹è¨“ç·´å¾ªç’°<br/>æœ€å¤š 1000 epochs]
    
    TrainLoop --> EpochEnd{Epoch çµæŸ}
    EpochEnd --> CheckBest{é©—è­‰æº–ç¢ºç‡<br/>æ˜¯å¦ç‚ºæœ€ä½³ï¼Ÿ}
    CheckBest -->|æ˜¯| SaveBest[ä¿å­˜æ–°çš„æœ€ä½³æ¬Šé‡<br/>åˆªé™¤èˆŠæ¬Šé‡]
    CheckBest -->|å¦| CheckLR{é©—è­‰æå¤±<br/>5 epochs æ²’æ”¹å–„ï¼Ÿ}
    SaveBest --> CheckLR
    
    CheckLR -->|æ˜¯| ReduceLR[å­¸ç¿’ç‡ Ã— 0.5]
    CheckLR -->|å¦| CheckEarly
    ReduceLR --> CheckEarly{é©—è­‰æå¤±<br/>10 epochs æ²’æ”¹å–„ï¼Ÿ}
    
    CheckEarly -->|æ˜¯| StopTrain[æ—©åœï¼šåœæ­¢è¨“ç·´<br/>æ¢å¾©æœ€ä½³æ¬Šé‡]
    CheckEarly -->|å¦| ContinueTrain{é”åˆ°<br/>æœ€å¤§ epochsï¼Ÿ}
    
    ContinueTrain -->|å¦| TrainLoop
    ContinueTrain -->|æ˜¯| StopTrain
    
    StopTrain --> LoadBest[è¼‰å…¥æœ€ä½³æ¬Šé‡]
    LoadBest --> PlotResults[ç¹ªè£½è¨“ç·´æ›²ç·š<br/>Loss / Accuracy]
    PlotResults --> Evaluate[è©•ä¼°é©—è­‰é›†]
    Evaluate --> FindErrors[æ‰¾å‡ºåˆ†é¡éŒ¯èª¤çš„æ¡ˆä¾‹]
    FindErrors --> PrintErrors[æ‰“å°éŒ¯èª¤è©³æƒ…<br/>- æª”æ¡ˆåç¨±<br/>- çœŸå¯¦/é æ¸¬æ¨™ç±¤<br/>- ä¿¡å¿ƒåº¦]
    PrintErrors --> ShowImages[é¡¯ç¤ºéŒ¯èª¤åœ–ç‰‡]
    ShowImages --> Cleanup[æ¸…ç†è‡¨æ™‚ç›®éŒ„]
    Cleanup --> End([è¨“ç·´å®Œæˆ])
```

---

| åƒæ•¸                         | å»ºè­°å€¼ | èªªæ˜               |
| ---------------------------- | ------ | ------------------ |
| `ReduceLROnPlateau.patience` | 5      | é©åˆä¸­ç­‰è¦æ¨¡è³‡æ–™é›† |
| `ReduceLROnPlateau.factor`   | 0.5    | æ¼¸é€²å¼é™ä½å­¸ç¿’ç‡   |
| `EarlyStopping.patience`     | 10     | çµ¦æ¨¡å‹å……åˆ†èª¿æ•´æ™‚é–“ |
| `train_ratio`                | 0.8    | ç¶“å…¸çš„ 80/20 åˆ†å‰²  |
| `batch_size`                 | 32     | å¹³è¡¡é€Ÿåº¦èˆ‡è¨˜æ†¶é«”   |
| `max_epochs`                 | 1000   | è¨­å®šé«˜å€¼ï¼Œä¾è³´æ—©åœ |

---

## ğŸ“Š è¨“ç·´çµæœèˆ‡æ­£ç¢ºç‡æ¯”è¼ƒ

### è‡ªå‹•ç”Ÿæˆè¨“ç·´æ›²ç·šåœ–

è¨“ç·´å®Œæˆå¾Œæœƒè‡ªå‹•ç”Ÿæˆ **`training_plots.png`**ï¼ŒåŒ…å«è¨“ç·´å’Œé©—è­‰çš„æå¤±èˆ‡æº–ç¢ºç‡æ¯”è¼ƒï¼š

```python
# ç¹ªè£½æå¤±å’Œæº–ç¢ºç‡æŠ˜ç·šåœ–
plt.figure(figsize=(12, 4))

# æå¤±åœ–
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# æº–ç¢ºç‡åœ–
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.savefig('training_plots.png')
plt.show()
```

### æ­£ç¢ºç‡æ¯”è¼ƒæµç¨‹

```mermaid
flowchart LR
    A[è¨“ç·´éç¨‹] --> B[è¨˜éŒ„æ¯å€‹ Epoch<br/>çš„æº–ç¢ºç‡]
    B --> C[è¨“ç·´æº–ç¢ºç‡<br/>Train Accuracy]
    B --> D[é©—è­‰æº–ç¢ºç‡<br/>Val Accuracy]
    C --> E{æ¯”è¼ƒå·®è·}
    D --> E
    E -->|å·®è·å°<5%| F[âœ… æ¨¡å‹æ³›åŒ–è‰¯å¥½]
    E -->|å·®è·å¤§>10%| G[âš ï¸ å¯èƒ½éæ“¬åˆ]
    
    style F fill:#90EE90
    style G fill:#FFB6C6
```